{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Model Subclassing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3x_9PFkQ8RKn",
        "WO5rMwZg8RKo",
        "X2IaVjoy8RKo",
        "M11vU0E08RKo"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HunderlineK/notebooks/blob/main/Model_Subclassing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqKOYKiu8RKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c96b49-8b82-47c7-8281-dedcaedb570b"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoDjO1zx8RKc"
      },
      "source": [
        "# Model subclassing and custom training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oSh_EkQ8RKc"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Model subclassing](#coding_tutorial_1)\n",
        " #### [2. Custom layers](#coding_tutorial_2)\n",
        " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
        " #### [4. Custom training loops](#coding_tutorial_4)\n",
        " #### [5. tf.function decorator](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q99pyds8RKd"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Model subclassing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPRGd8Ui8RKd"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6ZjSi-x8RKd"
      },
      "source": [
        "#### Create a simple model using the model subclassing API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peeDGtZT8RKd"
      },
      "source": [
        "# Build the model\n",
        "\n",
        "class MyModel(Model):\n",
        "    def __init__(self, units):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.dense = tf.keras.layers.Dense(units)\n",
        "    def call(self, inputs, training=False):\n",
        "        return self.dense(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gobxkF6F8RKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f42f5032-57c4-4e6a-b46b-539c08a8eb6b"
      },
      "source": [
        "# Print the model summary\n",
        "\n",
        "model = MyModel(1)\n",
        "model.build((None, 1))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              multiple                  2         \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz6CWrXM8RKe"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn04PMwo8RKe"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY1JuRXA8RKf"
      },
      "source": [
        "#### Create custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj3Sn8Kz8RKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc69a2b7-a469-4f44-efb1-292a4c656008"
      },
      "source": [
        "# Create a custom layer\n",
        "\n",
        "class SimpleDense(Layer):\n",
        "  def __init__(self, input_dim, units):\n",
        "    super(SimpleDense, self).__init__()\n",
        "    self.units = units\n",
        "    self.w = self.add_weight(shape=(input_dim, units), initializer=tf.random_normal_initializer())\n",
        "    self.b = self.add_weight(shape=(units), initializer=tf.zeros_initializer())\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "simple_dense = SimpleDense(3, 1)\n",
        "x = [tf.constant((4, 3, 2), dtype=\"float32\")]\n",
        "print(simple_dense(x))\n",
        "print(simple_dense.trainable_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[-0.47028118]], shape=(1, 1), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
            "array([[-0.10946687],\n",
            "       [-0.0304388 ],\n",
            "       [ 0.02945134]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNtonvt88RKf"
      },
      "source": [
        "# Specify trainable weights\n",
        "\n",
        "\n",
        "class SimpleDense(Layer):\n",
        "  def __init__(self, input_dim, units):\n",
        "    super(SimpleDense, self).__init__()\n",
        "    self.units = units\n",
        "    self.w = self.add_weight(shape=(input_dim, units), initializer=tf.random_normal_initializer())\n",
        "    self.b = self.add_weight(shape=(units), initializer=tf.zeros_initializer(), trainable=False)\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "simple_dense = SimpleDense(3, 1)\n",
        "x = [tf.constant((4, 3, 2), dtype=\"float32\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfYrDisL8RKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ae3058-325d-4a95-da3f-d0d9dbf7af55"
      },
      "source": [
        "print('trainable weights:', simple_dense.trainable_weights)\n",
        "print('non-trainable weights:', simple_dense.non_trainable_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainable weights: [<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
            "array([[0.05632761],\n",
            "       [0.0780715 ],\n",
            "       [0.04850844]], dtype=float32)>]\n",
            "non-trainable weights: [<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soDjsr-R8RKf"
      },
      "source": [
        "# Create a custom layer to accumulate means of output values\n",
        "\n",
        "class ActivationsMean(Layer):\n",
        "  def __init__(self, units, input_dim):\n",
        "    super(ActivationsMean, self).__init__()\n",
        "    self.units = units\n",
        "    self.w = self.add_weight(shape=(input_dim, units), initializer=tf.random_normal_initializer())\n",
        "    self.b = self.add_weight(shape=(units), initializer=tf.zeros_initializer())\n",
        "    self.num_calls = tf.Variable(0)\n",
        "    self.activations_sum = tf.Variable(tf.zeros(units))\n",
        "  def call(self, inputs):\n",
        "    activations = tf.matmul(inputs, self.w) + self.b\n",
        "    self.num_calls.assign_add(inputs.shape[0])\n",
        "    self.activations_sum.assign_add(tf.reduce_sum(activations, axis=0))\n",
        "    return activations, self.activations_sum / tf.cast(self.num_calls, dtype=\"float32\")\n",
        "  \n",
        "activations_mean = ActivationsMean(units=3, input_dim=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9-WaMkh8RKg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "228c29d3-8db9-4f3e-a930-2794136b290b"
      },
      "source": [
        "# Test the layer\n",
        "\n",
        "y, activation_means = activations_mean(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.09037036 -0.2020526   0.16883661]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS_cDzzG8RKg"
      },
      "source": [
        "# Create a Dropout layer as a custom layer\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, rate=self.rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJJPc5fi8RKg"
      },
      "source": [
        "#### Implement the custom layers into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLV6KZDG8RKg"
      },
      "source": [
        "# Build the model using custom layers with the model subclassing API\n",
        "\n",
        "class MyModel(Model):\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.dense_1 = SimpleDense(input_dim_1, units_1)\n",
        "        self.dropout_1 = MyDropout(0.7)\n",
        "        self.dense_2 = SimpleDense(units_1, units_2)\n",
        "        self.dropout_2 = MyDropout(0.7)\n",
        "        self.dense_3 = SimpleDense(units_2, units_3)\n",
        "           \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        h = self.dense_1(inputs)\n",
        "        h = self.dropout_1(h)\n",
        "        h = self.dense_2(h)\n",
        "        h = self.dropout_2(h)\n",
        "        return self.dense_3(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzL8hr6C8RKg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35064351-c7d0-4a6d-ea39-50ae89cb18ef"
      },
      "source": [
        "# Instantiate a model object\n",
        "\n",
        "model = MyModel(64,10000,64,46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 1.1130168  -1.9405086  -0.9035058   4.8536034  -0.19616146 -0.19793004\n",
            "  -0.4119551  -2.231533    0.21389516  1.5264114  -0.06521636  2.8056967\n",
            "   2.1658113   0.08040199  0.8826734  -1.6868404  -0.7327321   1.4152582\n",
            "  -3.535544    0.17693329 -2.971482   -1.9056319  -2.935541   -0.13452011\n",
            "  -0.00566787 -2.4229639  -4.081917    2.0636582   2.8587728  -1.7552518\n",
            "  -1.8000066   0.6231221  -3.164719   -1.6298279   0.29169396  1.183894\n",
            "   0.17411514 -3.159477   -0.20334071  3.343568    1.4505521   2.4944737\n",
            "   0.36954775 -2.3430796   3.0455208   1.8699613 ]], shape=(1, 46), dtype=float32)\n",
            "Model: \"my_model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_dense_22 (SimpleDense multiple                  640064    \n",
            "_________________________________________________________________\n",
            "my_dropout_12 (MyDropout)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "simple_dense_23 (SimpleDense multiple                  4160      \n",
            "_________________________________________________________________\n",
            "my_dropout_13 (MyDropout)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "simple_dense_24 (SimpleDense multiple                  2990      \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 647,040\n",
            "Non-trainable params: 174\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1NojPLy8RKg"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## Automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi69P8v18RKh"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHotQf-r8RKh"
      },
      "source": [
        "#### Create synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT1aMp838RKh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "9f9655f1-4aa8-4468-a41a-8e55fa3eb21b"
      },
      "source": [
        "# Create data from a noise contaminated linear model\n",
        "\n",
        "def MakeNoisyData(m, b, n=20):\n",
        "    x = tf.random.uniform(shape=(n,))\n",
        "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
        "    y = m * x + b + noise\n",
        "    return x, y\n",
        "\n",
        "w=1\n",
        "m=0.75\n",
        "b=2\n",
        "x_train, y_train = MakeNoisyData(m,b)\n",
        "plt.plot(x_train, y_train, 'b.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f17d97bae50>]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVc3RMjx8RKh"
      },
      "source": [
        "#### Define a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XgmAMcm8RKh"
      },
      "source": [
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_zauJSf8RKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aede150-2ee7-4213-fc13-12e3c08d11ec"
      },
      "source": [
        "# Build a custom layer for the linear regression model\n",
        "\n",
        "class LinearRegression(Layer):\n",
        "  def __init__(self):\n",
        "    super(LinearRegression, self).__init__()\n",
        "  def build(self, input_shape):\n",
        "    self.w = self.add_weight(shape=(input_shape[-1], 1), initializer=tf.random_normal_initializer())\n",
        "    self.b = self.add_weight(shape=(1), initializer=tf.zeros_initializer())\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "  \n",
        "linear_regression = LinearRegression()\n",
        "linear_regression.trainable_variables"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkMyJPkP8RKi"
      },
      "source": [
        "#### Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTffzfCR8RKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6797819e-fcf5-4557-d31e-977d6bebf2c1"
      },
      "source": [
        "# Define the mean squared error loss function\n",
        "\n",
        "def SquaredError(y_pred, y_true):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
        "\n",
        "y_pred = linear_regression(tf.expand_dims(x_train, -1))\n",
        "starting_loss = SquaredError(y_pred, y_train)\n",
        "print(\"Starting loss\", starting_loss.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting loss 5.6472344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AGlJsVe8RKi"
      },
      "source": [
        "#### Train and plot the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUi0oMFr8RKi"
      },
      "source": [
        "# Implement a gradient descent training loop for the linear regression model\n",
        "\n",
        "learning_rate = 0.05\n",
        "steps = 25\n",
        "\n",
        "for s in range(steps):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred = linear_regression(tf.expand_dims(x_train, -1))\n",
        "    loss = SquaredError(y_pred, y_train)\n",
        "\n",
        "  gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
        "\n",
        "  linear_regression.w.assign_sub(learning_rate * gradients[0])\n",
        "  linear_regression.b.assign_sub(learning_rate * gradients[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CZtLoKd8RKi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afe3d94a-f84c-4600-cda5-f4bf9b5eacdb"
      },
      "source": [
        "# Plot the learned regression model\n",
        "\n",
        "print(\"w:{},  trained w:{}\".format(w,linear_regression.w.numpy()))\n",
        "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
        "\n",
        "plt.plot(x_train, y_train, 'b.')\n",
        "\n",
        "x_linear_regression=[np.linspace(min(x_train), max(x_train),50)]\n",
        "plt.plot(x_linear_regression, linear_regression.w*x_linear_regression+linear_regression.b, 'r.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w:1,  trained w:[[0.8304185]]\n",
            "b:2,  trained b:[1.8485436]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f17d990bc90>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e61fdb10>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e61fdcd0>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e61fde90>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e61fdd10>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6201110>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6201150>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6201190>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e62014d0>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6201a90>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6201890>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6201310>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6201e90>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6201a50>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6200090>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6200150>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6200310>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e62004d0>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6200690>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6200850>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6200a10>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6200e90>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6200190>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e61f6090>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e61f6150>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e61f6310>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e61f64d0>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e61f6690>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e61f6850>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e61f6a10>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e61f6e90>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e61f6190>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6213090>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6213150>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6213310>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e62134d0>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6213690>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6213850>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6213a10>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6213e90>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6213190>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6214090>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6214150>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6214310>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e62144d0>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6214690>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6214850>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6214a10>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6214e90>,\n",
              " <matplotlib.lines.Line2D at 0x7f17e6214190>]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fBbA8x58RKi"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## Custom training loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dAiJUtk8RKj"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfES8AoI8RKj"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r4eJsjH8RKj"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1iyK_tj8RKj"
      },
      "source": [
        "#### Load the reuters dataset and define the class_names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un4W_xHV8RKj"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "\n",
        "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
        "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
        "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
        "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhhPoz4H8RKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7df136a6-e695-428e-8e2e-fe4c9107c38c"
      },
      "source": [
        "# Print the class of the first sample\n",
        "\n",
        "print(\"Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: earn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9kYsaBC8RKk"
      },
      "source": [
        "#### Get the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdn4DUuP8RKk"
      },
      "source": [
        "# Load the Reuters word index\n",
        "\n",
        "word_to_index = reuters.get_word_index()\n",
        "\n",
        "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLrIVHk78RKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802b547f-94ab-4637-ab9d-236f57f22b69"
      },
      "source": [
        "# Print the first data example sentence\n",
        "\n",
        "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])\n",
        "print(text_news)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQAnoWwm8RKk"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMKPOVwn8RKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb13a3fb-1a38-45b1-b9ae-61bc82e0cd6e"
      },
      "source": [
        "# Define a function that encodes the data into a 'bag of words' representation\n",
        "\n",
        "def bag_of_words(text_samples, elements=10000):\n",
        "    output = np.zeros((len(text_samples), elements))\n",
        "    for i, word in enumerate(text_samples):\n",
        "        output[i, word] = 1.\n",
        "    return output\n",
        "\n",
        "x_train = bag_of_words(train_data)\n",
        "x_test = bag_of_words(test_data)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train: (8982, 10000)\n",
            "Shape of x_test: (2246, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n-i8PdA8RKl"
      },
      "source": [
        "#### Define the loss function and optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFD-GYP-8RKl"
      },
      "source": [
        "# Define the categorical cross entropy loss and Adam optimizer\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def loss(model, x, y, wd):\n",
        "    kernel_variables = []\n",
        "    for l in model.layers:\n",
        "        for w in l.weights:\n",
        "            if 'kernel' in w.name:\n",
        "                kernel_variables.append(w)\n",
        "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
        "    y_ = model(x)\n",
        "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv-bLWgh8RKl"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixvHlLmy8RKl"
      },
      "source": [
        "# Define a function to compute the forward and backward pass\n",
        "\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IDOyBb48RKm"
      },
      "source": [
        "# Implement the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "epochs=16\n",
        "weight_decay = 0.005\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels)).batch(batch_size)\n",
        "\n",
        "def train(dataset):\n",
        "  train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "  train_loss_metric = tf.keras.metrics.Mean()\n",
        "\n",
        "  train_loss_results=[]\n",
        "  train_accuracy_results=[]\n",
        "  for epoch in np.arange(epochs):\n",
        "    for step, (x, y) in enumerate(train_dataset):\n",
        "      loss_value, grads = grad(model, x, y, weight_decay)\n",
        "      # Processing aggregated gradients.\n",
        "      optimizer.apply_gradients(zip(grads,  model.trainable_variables), experimental_aggregate_gradients=False)\n",
        "      \n",
        "      # Update training metric.\n",
        "      train_acc_metric.update_state(y, model(x))\n",
        "      train_loss_metric.update_state(loss_value)\n",
        "\n",
        "      # Log every 200 batches.\n",
        "      if step % 100 == 0:\n",
        "          print(\n",
        "              \"Training loss (for one batch) at step %d: %.4f\"\n",
        "              % (step, float(loss_value))\n",
        "          )\n",
        "          print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
        "\n",
        "    # Display metrics at the end of each epoch.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    train_loss = train_loss_metric.result()\n",
        "    train_acc_metric.reset_states()\n",
        "    train_loss_metric.reset_states()\n",
        "    train_accuracy_results.append(train_acc)\n",
        "    train_loss_results.append(train_loss)\n",
        "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "    print(\"Training loss over epoch: %.4f\" % (float(train_loss),))\n",
        "  return train_loss_results, train_accuracy_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyVBX_0Ut5-7"
      },
      "source": [
        "# Define the custom layers and model\n",
        "\n",
        "class SimpleDense(Layer):\n",
        "  def __init__(self, units):\n",
        "    super(SimpleDense, self).__init__()\n",
        "    self.units = units\n",
        "  def build(self, input_shape):\n",
        "    self.w = self.add_weight(shape=(input_shape[-1], self.units), initializer=tf.random_normal_initializer(), name='kernel')\n",
        "    self.b = self.add_weight(shape=(self.units), initializer=tf.zeros_initializer(), name='bias')\n",
        "  def call(self, inputs):\n",
        "    return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "class MyDropout(Layer):\n",
        "  def __init__(self, rate):\n",
        "    super(MyDropout, self).__init__()\n",
        "    self.rate = rate\n",
        "      \n",
        "  def call(self, inputs, training):\n",
        "    # Define forward pass for dropout layer\n",
        "    if (training):\n",
        "      return tf.nn.dropout(inputs, rate=self.rate)\n",
        "    return inputs\n",
        "\n",
        "class MyModel(Model):\n",
        "  def __init__(self, units_1, units_2, units_3):\n",
        "    super(MyModel, self).__init__()\n",
        "    # Define layers\n",
        "    self.dense_1 = SimpleDense(units_1)\n",
        "    self.dropout_1 = MyDropout(0.7)\n",
        "    self.dense_2 = SimpleDense(units_2)\n",
        "    self.dropout_2 = MyDropout(0.7)\n",
        "    self.dense_3 = SimpleDense(units_3)\n",
        "  def call(self, inputs, training):\n",
        "    # Define forward pass\n",
        "    h = self.dense_1(inputs)\n",
        "    h = self.dropout_1(h, training=training)\n",
        "    h = self.dense_2(h)\n",
        "    h = self.dropout_2(h, training=training)\n",
        "    return tf.nn.softmax(self.dense_3(h))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmYahTVQz_i1",
        "outputId": "4812a679-3ad0-4ae3-a2be-167d54a6a3ba"
      },
      "source": [
        "model = MyModel(16, 16, len(class_names))  \n",
        "model(np.asarray([x_train[0]]))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_dense_25 (SimpleDense multiple                  160016    \n",
            "_________________________________________________________________\n",
            "my_dropout_14 (MyDropout)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "simple_dense_26 (SimpleDense multiple                  272       \n",
            "_________________________________________________________________\n",
            "my_dropout_15 (MyDropout)    multiple                  0         \n",
            "_________________________________________________________________\n",
            "simple_dense_27 (SimpleDense multiple                  782       \n",
            "=================================================================\n",
            "Total params: 161,070\n",
            "Trainable params: 161,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzIZMupsw5Dg",
        "outputId": "6ad18587-1931-41ca-bf13-cd358ef27efd"
      },
      "source": [
        "start_time = time.time()\n",
        "train_loss_results, train_accuracy_results = train(train_dataset)\n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss (for one batch) at step 0: 5.8518\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 2.2301\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.6487\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.4325\n",
            "Training loss over epoch: 2.5859\n",
            "Training loss (for one batch) at step 0: 1.2715\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.6354\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.3380\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.5957\n",
            "Training loss over epoch: 1.7739\n",
            "Training loss (for one batch) at step 0: 1.1425\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.5312\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.2417\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.6593\n",
            "Training loss over epoch: 1.6562\n",
            "Training loss (for one batch) at step 0: 1.1475\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.4346\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.1835\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.6880\n",
            "Training loss over epoch: 1.5900\n",
            "Training loss (for one batch) at step 0: 1.1834\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.3581\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.1318\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7015\n",
            "Training loss over epoch: 1.5473\n",
            "Training loss (for one batch) at step 0: 1.1916\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.3084\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.0915\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7099\n",
            "Training loss over epoch: 1.5178\n",
            "Training loss (for one batch) at step 0: 1.1859\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.2747\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.0628\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7163\n",
            "Training loss over epoch: 1.4951\n",
            "Training loss (for one batch) at step 0: 1.1762\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.2494\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.0433\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7220\n",
            "Training loss over epoch: 1.4756\n",
            "Training loss (for one batch) at step 0: 1.1652\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.2283\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.0311\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7285\n",
            "Training loss over epoch: 1.4578\n",
            "Training loss (for one batch) at step 0: 1.1526\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.2110\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.0253\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7356\n",
            "Training loss over epoch: 1.4404\n",
            "Training loss (for one batch) at step 0: 1.1400\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.1998\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.0261\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7478\n",
            "Training loss over epoch: 1.4237\n",
            "Training loss (for one batch) at step 0: 1.1302\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.1933\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.0285\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7576\n",
            "Training loss over epoch: 1.4096\n",
            "Training loss (for one batch) at step 0: 1.1237\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.1866\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.0279\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7635\n",
            "Training loss over epoch: 1.3986\n",
            "Training loss (for one batch) at step 0: 1.1201\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.1802\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.0265\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7678\n",
            "Training loss over epoch: 1.3896\n",
            "Training loss (for one batch) at step 0: 1.1182\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.1737\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.0248\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7707\n",
            "Training loss over epoch: 1.3819\n",
            "Training loss (for one batch) at step 0: 1.1167\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.1664\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.0226\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7735\n",
            "Training loss over epoch: 1.3748\n",
            "Duration :65.291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaRmHgxY8RKm"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNwQx-hQ8RKm"
      },
      "source": [
        "# Create a Dataset object for the test set\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0in6_8vv8RKm"
      },
      "source": [
        "# Collect average loss and accuracy\n",
        "\n",
        "epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iebYHCKx8RKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb7d0327-43b2-4f08-fbfa-7e72b05dfa28"
      },
      "source": [
        "# Loop over the test set and print scores\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "for x, y in test_dataset:\n",
        "    # Optimize the model\n",
        "    weight_decay = 0.01\n",
        "    loss_value = loss(model, x, y, weight_decay)\n",
        "    # Compute current loss\n",
        "    epoch_loss_avg(loss_value)\n",
        "    # Compare predicted label to actual label\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
        "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 2.030\n",
            "Test accuracy: 70.614%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ_O2jcP8RKm"
      },
      "source": [
        "#### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En-t44Ao8RKn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "071119c0-f88d-452d-d9e3-2623d7980a4b"
      },
      "source": [
        "# Plot the training loss and accuracy\n",
        "\n",
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bYY2Kir8RKn"
      },
      "source": [
        "#### Predict from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXLtMzpX8RKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b48fbbb-d3d7-4e64-faec-77fba3109de9"
      },
      "source": [
        "# Get the model prediction for an example input\n",
        "\n",
        "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
        "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
        "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: earn\n",
            "     Label: earn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWV1Pkrv8RKn"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyEQ4Lp-8RKn"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x_9PFkQ8RKn"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLOJ5hn-8RKn"
      },
      "source": [
        "# Initialize a new model\n",
        "\n",
        "model = MyModel(16, 16, len(class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO5rMwZg8RKo"
      },
      "source": [
        "#### Redefine the grad function using the @tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEguZT0b8RKo"
      },
      "source": [
        "# Use the @tf.function decorator\n",
        "\n",
        "@tf.function\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2IaVjoy8RKo"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyxKarhm8RKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e6708e6-11a6-4129-ca8a-43395d09e5a4"
      },
      "source": [
        "# Re-run the training loop\n",
        "\n",
        "start_time = time.time()\n",
        "train(train_dataset)\n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss (for one batch) at step 0: 7.8452\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.8143\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.5320\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.5596\n",
            "Training loss over epoch: 2.1987\n",
            "Training loss (for one batch) at step 0: 1.3244\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.6477\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.4145\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.6583\n",
            "Training loss over epoch: 1.8311\n",
            "Training loss (for one batch) at step 0: 1.3280\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.5597\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.3584\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.6823\n",
            "Training loss over epoch: 1.7666\n",
            "Training loss (for one batch) at step 0: 1.3255\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.5068\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.3226\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.6926\n",
            "Training loss over epoch: 1.7297\n",
            "Training loss (for one batch) at step 0: 1.3108\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.4693\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.2982\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.6983\n",
            "Training loss over epoch: 1.7053\n",
            "Training loss (for one batch) at step 0: 1.2913\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.4431\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.2803\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7011\n",
            "Training loss over epoch: 1.6875\n",
            "Training loss (for one batch) at step 0: 1.2714\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.4269\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.2665\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7040\n",
            "Training loss over epoch: 1.6734\n",
            "Training loss (for one batch) at step 0: 1.2526\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.4191\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.2556\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7080\n",
            "Training loss over epoch: 1.6615\n",
            "Training loss (for one batch) at step 0: 1.2361\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.4141\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.2465\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7106\n",
            "Training loss over epoch: 1.6510\n",
            "Training loss (for one batch) at step 0: 1.2215\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.4080\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.2382\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7118\n",
            "Training loss over epoch: 1.6416\n",
            "Training loss (for one batch) at step 0: 1.2067\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.4008\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.2305\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7138\n",
            "Training loss over epoch: 1.6331\n",
            "Training loss (for one batch) at step 0: 1.1920\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.3932\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.2238\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7171\n",
            "Training loss over epoch: 1.6255\n",
            "Training loss (for one batch) at step 0: 1.1787\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.3857\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.2183\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7197\n",
            "Training loss over epoch: 1.6187\n",
            "Training loss (for one batch) at step 0: 1.1677\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.3784\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.2140\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7211\n",
            "Training loss over epoch: 1.6124\n",
            "Training loss (for one batch) at step 0: 1.1592\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.3716\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.2110\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7239\n",
            "Training loss over epoch: 1.6067\n",
            "Training loss (for one batch) at step 0: 1.1530\n",
            "Seen so far: 32 samples\n",
            "Training loss (for one batch) at step 100: 1.3656\n",
            "Seen so far: 3232 samples\n",
            "Training loss (for one batch) at step 200: 1.2090\n",
            "Seen so far: 6432 samples\n",
            "Training acc over epoch: 0.7248\n",
            "Training loss over epoch: 1.6014\n",
            "Duration :43.872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M11vU0E08RKo"
      },
      "source": [
        "#### Print the autograph code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxtXU0Eg8RKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d52638c4-860f-4883-ae3c-414a474d9bd5"
      },
      "source": [
        "# Use tf.autograph.to_code to see the generated code\n",
        "\n",
        "print(tf.autograph.to_code(grad.python_function))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def tf__grad(model, inputs, targets, wd):\n",
            "    with ag__.FunctionScope('grad', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
            "        do_return = False\n",
            "        retval_ = ag__.UndefinedReturnValue()\n",
            "        with ag__.ld(tf).GradientTape() as tape:\n",
            "            loss_value = ag__.converted_call(ag__.ld(loss), (ag__.ld(model), ag__.ld(inputs), ag__.ld(targets), ag__.ld(wd)), None, fscope)\n",
            "        try:\n",
            "            do_return = True\n",
            "            retval_ = (ag__.ld(loss_value), ag__.converted_call(ag__.ld(tape).gradient, (ag__.ld(loss_value), ag__.ld(model).trainable_variables), None, fscope))\n",
            "        except:\n",
            "            do_return = False\n",
            "            raise\n",
            "        return fscope.ret(retval_, do_return)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}